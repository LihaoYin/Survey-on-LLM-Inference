# Survey-on-LLM-Inference

## Contents

- [0. Introduction](#0-Introduction) <br />

- [1. Paper Reading Progress](#1-Paper-Reading-Progress) <br />

- [2. All Papers (Classifications according to Related Topics)](#2-all-papers-classifications-according-to-related-topics) <br />

- [3. All Paper Survey](#3-all-paper-survey) <br />


## 0. Introduction

### Contributor

### Taxonomy

![Taxonomy of Efficient LLM Inference](https://github.com/LihaoYin/Survey-on-LLM-Inference/blob/main/Images/Taxonomy.png)

## 1. Paper Reading Progress



| Paper Title | Taxonomy | Reader | Link |
| :-------------------------------------------------------------| :-------- | :-------- | :--------|


## 2. All Papers (Classifications according to Taxonomy)
- **大算子**

- **Quantization**

- **Structure Optimization**

- **Knowledge Distillation**

- **Dynamic Inference**

- **System-level Optimization**

- **Retrieval-Augmented Generation (RAG)**


## 3. All Paper Survey

### SpecInfer: Accelerating Large Language Model Serving with Tree-based Speculative Inference and Verification (ASPLOS 2024)

* <img src="Image/pdf_24px.png">[Paper](https://dl.acm.org/doi/abs/10.1145/3620666.3651335)
**Taxonomy:** Dynamic Inference
  
**Notes:** 
